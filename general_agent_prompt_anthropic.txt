# Complete AI Agent System Implementation Prompt - Anthropic API

You are tasked with creating a complete Python AI agent system using Anthropic's API with tool calling support. This system should be minimal yet powerful, leveraging Anthropic's Claude models for custom endpoint support and advanced reasoning capabilities.

## Overview

This project will create a simplified AI coding agent with three main components:
1. **Agent Loop** - Use Anthropic API powered conversation loop with multi-turn conversations and tool calling
2. **Tool System** - File operations and code execution tools with comprehensive logging
3. **Chat Interface** - Interactive command-line REPL interface for user interaction

## Model Provider Integration

The system uses a custom model provider that wraps Anthropic's client. Create a `model_provider.py` file that supports:
- Custom API endpoints via `ANTHROPIC_BASE_URL` environment variable
- API key configuration via `ANTHROPIC_API_KEY` environment variable  
- Model selection via `ANTHROPIC_MODEL_NAME` environment variable
- Automatic Anthropic client creation with custom base URLs

### Custom Model Provider Implementation
```python
# model_provider.py
import os
from typing import Optional, List, Dict, Any
from dotenv import load_dotenv
from anthropic import Anthropic

# Load environment variables from .env file
load_dotenv(override=True)

class AnthropicModelProvider:
    """Custom model provider for Anthropic API"""
    
    def __init__(self):
        # Load configuration from environment variables
        self.base_url = os.getenv("ANTHROPIC_BASE_URL", "https://api.anthropic.com")
        self.api_key = os.getenv("ANTHROPIC_API_KEY", "")
        self.model_name = os.getenv("ANTHROPIC_MODEL_NAME", "claude-4-sonnet-20250514")
        
        # Validate required configuration
        if not self.api_key:
            raise ValueError(
                "ANTHROPIC_API_KEY environment variable must be set. "
                "Please add it to your .env file or environment variables."
            )
        
        # Create Anthropic client with custom base URL
        self.client = Anthropic(
            api_key=self.api_key,
            base_url=self.base_url
        )
    
    def create_message(self, messages: List[Dict[str, Any]], tools: List[Dict[str, Any]], 
                      system_prompt: str = "", max_tokens: int = 4096) -> Dict[str, Any]:
        """Create a message with tool calling support"""
        try:
            params = {
                "model": self.model_name,
                "max_tokens": max_tokens,
                "system": system_prompt,
                "messages": messages
            }
            if tools:
                params["tools"] = tools
            
            response = self.client.messages.create(**params)
            return response
        except Exception as e:
            raise RuntimeError(f"Error creating message: {str(e)}")

# Create global instance
DEFAULT_MODEL_PROVIDER = AnthropicModelProvider()
```

## Part 1: Agent Loop Implementation

### Requirements
- Use Anthropic API with tool calling support
- Load system prompt from a local file (`system_prompt.txt`)
- Integrate tools from Part 2 using Anthropic's tool format
- Handle conversation history and context
- Support multi-turn conversations with tool execution

### Core Components

All components are implemented in a single `agent.py` file:

#### Agent Class
```python
import json
import os
from typing import List, Dict, Any, Optional
from model_provider import DEFAULT_MODEL_PROVIDER

class ChatAgent:
    def __init__(self, system_prompt_file: str = "system_prompt.txt", 
                 model_name: str = "claude-4-sonnet-20250514"):
        """Initialize the agent with system prompt and model configuration"""
        self.system_prompt_file = system_prompt_file
        self.model_name = model_name
        self.system_prompt = self.load_system_prompt()
        self.tools = []
        self.tool_functions = {}
        self.conversation_history = []
        self.max_turns = int(os.getenv("MAX_TURNS", "100"))
        
    def load_system_prompt(self) -> str:
        """Load system prompt from file"""
        try:
            with open(self.system_prompt_file, 'r', encoding='utf-8') as f:
                return f.read().strip()
        except FileNotFoundError:
            return "You are a helpful AI assistant with useful tools."
        
    def register_tools(self, tools: List[Dict[str, Any]], tool_functions: Dict[str, callable]):
        """Register tools with the agent"""
        self.tools = tools
        self.tool_functions = tool_functions
        
    async def run_conversation(self, user_input: str) -> str:
        """Run the main conversation loop"""
        # Add user message to history
        self.conversation_history.append({
            "role": "user",
            "content": user_input
        })
        
        turn_count = 0
        while turn_count < self.max_turns:
            try:
                # Create message with current history
                response = DEFAULT_MODEL_PROVIDER.create_message(
                    messages=self.conversation_history,
                    tools=self.tools,
                    system_prompt=self.system_prompt
                )
                
                # Add assistant response to history
                assistant_content = []
                
                # Handle different content types
                for content_block in response.content:
                    if content_block.type == "text":
                        assistant_content.append({
                            "type": "text",
                            "text": content_block.text
                        })
                    elif content_block.type == "tool_use":
                        assistant_content.append({
                            "type": "tool_use",
                            "id": content_block.id,
                            "name": content_block.name,
                            "input": content_block.input
                        })
                
                # Only add assistant message if it has content
                if assistant_content:
                    assistant_message = {
                        "role": "assistant",
                        "content": assistant_content
                    }
                    self.conversation_history.append(assistant_message)
                
                # Check if response contains tool calls
                if response.stop_reason == "tool_use":
                    # Process tool calls
                    tool_results = []
                    for content_block in response.content:
                        if content_block.type == "tool_use":
                            tool_name = content_block.name
                            tool_input = content_block.input
                            tool_id = content_block.id
                            
                            # Execute tool
                            if tool_name in self.tool_functions:
                                try:
                                    result = self.tool_functions[tool_name](**tool_input)
                                    tool_results.append({
                                        "tool_use_id": tool_id,
                                        "content": str(result)
                                    })
                                except Exception as e:
                                    tool_results.append({
                                        "tool_use_id": tool_id,
                                        "content": f"Error: {str(e)}"
                                    })
                    
                    # Add tool results to history
                    if tool_results:
                        formatted_tool_results = []
                        for result in tool_results:
                            formatted_tool_results.append({
                                "type": "tool_result",
                                "tool_use_id": result["tool_use_id"],
                                "content": result["content"]
                            })
                        
                        self.conversation_history.append({
                            "role": "user",
                            "content": formatted_tool_results
                        })
                        turn_count += 1
                        continue
                
                # Return final response
                text_content = ""
                for content_block in response.content:
                    if content_block.type == "text":
                        text_content += content_block.text
                
                return text_content
                
            except Exception as e:
                return f"Error in conversation: {str(e)}"
            
            turn_count += 1
        
        return "Conversation reached maximum turns limit."
        
    def reset_conversation(self):
        """Reset conversation history"""
        self.conversation_history = []
```

### File Structure
```
agent.py
```

## Part 2: Tool System Implementation

### Requirements
- Implement file operations and code execution tools using Anthropic's tool format
- Add comprehensive logging with format: `print(f"[TOOL][{tool_name}] {parameters}")`
- Handle errors gracefully with meaningful messages
- Follow Anthropic's tool calling specification

### Tool Categories
All tools are implemented in a single `tools.py` file:
1. **Communication Tools**: message_notify_user
2. **File Tools**: create_file, read_file, read_file_lines, replace_string_in_file, list_directory, create_directory, delete_file, delete_directory, get_file_info
3. **Code Tools**: execute_shell_command, execute_python_code, execute_python_file

### Workspace Context Integration
**CRITICAL:** The system uses a centralized workspace context for session isolation:

- **WorkspaceContext Class**: Integrated into `chat.py` to manage workspace state
- **Context Setting**: Chat interface sets workspace via `workspace_context.set_workspace()`
- **Tool Integration**: All tools import `workspace_context` from `chat.py`
- **Path Management**: Tools use `workspace_context.get_absolute_path()` for proper paths
- **Execution Context**: Commands run in workspace directory via `cwd=workspace_path`
- **Error Messages**: Include workspace context for better debugging
- **Fallback Support**: Tools work even without workspace context for testing

### Available Tools

**Communication:**
- message_notify_user(text, attachments) - Send message to user without requiring a response

**File Management:**
- create_file(file_path, content) - Create/overwrite file
- read_file(file_path) - Read file content
- read_file_lines(file_path, start_line, end_line) - Read specific lines
- replace_string_in_file(file_path, old_string, new_string) - Replace text
- delete_file(file_path) - Delete file
- get_file_info(file_path) - Get file info/stats

**Directory Management:**
- list_directory(directory_path, show_hidden, recursive) - List contents
- create_directory(directory_path) - Create directory
- delete_directory(directory_path) - Delete directory

**Code Execution:**
- execute_shell_command(command, timeout) - Run shell commands
- execute_python_code(code) - Execute Python code
- execute_python_file(file_path) - Run Python file

### Example Tool Implementation (Anthropic Format)
```python
import os
import subprocess
from typing import Dict, Any, List

# Import workspace context from chat module
from chat import workspace_context

# Anthropic tool definitions
ANTHROPIC_TOOLS = [
    {
        "name": "message_notify_user",
        "description": "Send a message to user without requiring a response. Use for acknowledging receipt of messages, providing progress updates, reporting task completion, or explaining changes in approach.",
        "input_schema": {
            "type": "object",
            "properties": {
                "text": {
                    "type": "string",
                    "description": "Message text to display to user"
                },
                "attachments": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "(Optional) List of attachments to show to user, can be file paths or URLs",
                    "default": []
                }
            },
            "required": ["text"]
        }
    },
    {
        "name": "create_file",
        "description": "Create a file at the specified path, will overwrite if it already exists.",
        "input_schema": {
            "type": "object",
            "properties": {
                "file_path": {
                    "type": "string",
                    "description": "The path of the file to create"
                },
                "content": {
                    "type": "string",
                    "description": "The content to write to the file",
                    "default": ""
                }
            },
            "required": ["file_path"]
        }
    },
    {
        "name": "execute_python_code",
        "description": "Execute Python code and return the output.",
        "input_schema": {
            "type": "object",
            "properties": {
                "code": {
                    "type": "string",
                    "description": "The Python code to execute"
                }
            },
            "required": ["code"]
        }
    },
    {
        "name": "execute_shell_command",
        "description": "Execute a shell command and return the output.",
        "input_schema": {
            "type": "object",
            "properties": {
                "command": {
                    "type": "string",
                    "description": "The shell command to execute"
                },
                "timeout": {
                    "type": "integer",
                    "description": "Timeout in seconds",
                    "default": 30
                }
            },
            "required": ["command"]
        }
    }
]

# Tool function implementations
def message_notify_user(text: str, attachments: List[str] = None) -> str:
    """Send a message to user without requiring a response."""
    try:
        print(f"[TOOL][message_notify_user] text={text[:100]}{'...' if len(text) > 100 else ''}")
        
        # Display the message
        message = f"🤖 {text}"
        
        # Handle attachments if provided
        if attachments:
            message += "\n📎 Attachments:"
            for attachment in attachments:
                if os.path.exists(attachment):
                    message += f"\n  - {attachment} (file exists)"
                else:
                    message += f"\n  - {attachment} (URL/reference)"
        
        # Print the message for the user to see
        print(message)
        
        return "Message sent to user successfully"
        
    except Exception as e:
        return f"Error sending message to user: {str(e)}"

def create_file(file_path: str, content: str = "") -> str:
    """Create a file at the specified path, will overwrite if it already exists."""
    try:
        # Handle directory creation
        dir_path = os.path.dirname(file_path)
        if dir_path:
            os.makedirs(dir_path, exist_ok=True)
        
        # Convert to absolute path using workspace context
        abs_file_path = workspace_context.get_absolute_path(file_path)
        
        print(f"[TOOL][create_file] file_path={abs_file_path}, content_length={len(content)}")

        with open(abs_file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return f"Successfully created file: {abs_file_path} (workspace: {workspace_context.get_workspace()})"
    except Exception as e:
        return f"Error creating file: {str(e)}"

def execute_python_code(code: str) -> str:
    """Execute Python code and return the output."""
    try:
        # Get workspace directory for execution
        workspace_path = workspace_context.get_workspace()
        
        print(f"[TOOL][execute_python_code] code_length={len(code)}")
        
        # Execute in workspace directory
        result = subprocess.run(
            ["python", "-c", code],
            cwd=workspace_path,
            capture_output=True,
            text=True,
            timeout=30
        )
        
        output = result.stdout
        if result.stderr:
            output += f"\nSTDERR:\n{result.stderr}"
        
        return output if output else "Code executed successfully (no output)"
        
    except subprocess.TimeoutExpired:
        return "Error: Code execution timed out"
    except Exception as e:
        return f"Error executing Python code: {str(e)}"

def execute_shell_command(command: str, timeout: int = 30) -> str:
    """Execute a shell command and return the output."""
    try:
        workspace_path = workspace_context.get_workspace()
        
        print(f"[TOOL][execute_shell_command] command={command}, timeout={timeout}")
        
        result = subprocess.run(
            command,
            shell=True,
            cwd=workspace_path,
            capture_output=True,
            text=True,
            timeout=timeout
        )
        
        output = result.stdout
        if result.stderr:
            output += f"\nSTDERR:\n{result.stderr}"
            
        return output if output else "Command executed successfully (no output)"
        
    except subprocess.TimeoutExpired:
        return f"Error: Command timed out after {timeout} seconds"
    except Exception as e:
        return f"Error executing shell command: {str(e)}"

# Tool function mapping
TOOL_FUNCTIONS = {
    "message_notify_user": message_notify_user,
    "create_file": create_file,
    "execute_python_code": execute_python_code,
    "execute_shell_command": execute_shell_command
}
```

### File Structure
```
tools.py
```

### Tools Export Function
```python
# At the end of tools.py, add:
def get_anthropic_tools():
    """Get all Anthropic tool definitions"""
    return ANTHROPIC_TOOLS

def get_tool_functions():
    """Get all tool function mappings"""
    return TOOL_FUNCTIONS
```

## Part 3: Chat Interface Implementation

### Requirements
- Create an interactive command-line REPL interface
- Auto-create `.env` file with API key configuration
- Support colored output and rich formatting
- Handle exit command (/exit)
- Show tool execution logs in real-time
- Create isolated workspace folders for each session

### Core Components

All components are implemented in a single `chat.py` file:

#### Chat Class
```python
import os
import asyncio
from dotenv import load_dotenv
from rich.console import Console
from rich.prompt import Prompt
from datetime import datetime
from typing import Optional

class WorkspaceContext:
    """Manages the current workspace context for tools and agents"""
    
    def __init__(self):
        self._workspace_path: Optional[str] = None
        self._original_cwd: Optional[str] = None
    
    def set_workspace(self, workspace_path: str) -> None:
        """Set the current workspace path and change to it"""
        self._original_cwd = os.getcwd()
        self._workspace_path = os.path.abspath(workspace_path)
        os.chdir(self._workspace_path)
    
    def get_workspace(self) -> Optional[str]:
        """Get the current workspace path"""
        return self._workspace_path
    
    def get_absolute_path(self, file_path: str) -> str:
        """Convert a file path to absolute, considering workspace context"""
        if self._workspace_path:
            if os.path.isabs(file_path):
                return file_path
            else:
                return os.path.abspath(os.path.join(self._workspace_path, file_path))
        return os.path.abspath(file_path)
    
    def __str__(self) -> str:
        return f"WorkspaceContext(workspace={self._workspace_path}, cwd={os.getcwd()})"

# Global workspace context instance
workspace_context = WorkspaceContext()

class AgentChat:
    def __init__(self, agent):
        """Initialize chat interface with agent instance"""
        self.agent = agent
        self.console = Console()
        self.workspace_folder = None
        
    async def start(self):
        """Start the interactive chat loop"""
        self.setup_workspace()
        self.display_welcome()
        
        while True:
            try:
                user_input = Prompt.ask("\n[bold green]>[/bold green]", console=self.console)
                
                if user_input.lower() in ['/exit', '/quit']:
                    self.handle_exit()
                    break
                    
                await self.handle_input(user_input)
                
            except KeyboardInterrupt:
                self.handle_exit()
                break
        
    def display_welcome(self):
        """Display welcome message and instructions"""
        self.console.print("\n🤖 AI Agent Chat v1.0 (Anthropic API)", style="bold blue")
        self.console.print("Welcome! Start chatting or type /exit to exit.")
        self.console.print(f"Working directory: {self.workspace_folder}")
        
    async def handle_input(self, user_input: str):
        """Process user input and display response"""
        try:
            # Show thinking indicator
            with self.console.status("[bold yellow]Thinking..."):
                response = await self.agent.run_conversation(user_input)
            
            self.display_response(response)
            
        except Exception as e:
            self.console.print(f"❌ Error: {str(e)}", style="bold red")
        
    def display_response(self, response: str):
        """Display agent response with formatting"""
        self.console.print(f"\n🤖 {response}", style="cyan")
        
    def handle_exit(self):
        """Handle exit command"""
        self.console.print("\nGoodbye! 👋", style="bold green")
        
    def create_env_file(self):
        """Create .env file with default configuration"""
        if not os.path.exists('.env'):
            env_content = """ANTHROPIC_API_KEY=your_api_key_here
ANTHROPIC_BASE_URL=https://api.anthropic.com
ANTHROPIC_MODEL_NAME=claude-4-sonnet-20250514
MAX_TURNS=100
SYSTEM_PROMPT_FILE=system_prompt.txt"""
            with open('.env', 'w') as f:
                f.write(env_content)
            self.console.print("✅ Created .env file - Please update with your API key")
        
    def load_environment(self):
        """Load environment variables from .env file"""
        load_dotenv()
        
    def setup_workspace(self):
        """Set up working directory and required files"""
        self.load_environment()
        self.create_env_file()
        self.create_workspace_folder()
        self.install_dependencies()
        
    def create_workspace_folder(self):
        """Create a new workspace folder for each run (workspace/session_id)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.workspace_folder = f"workspace/session_{timestamp}"
        os.makedirs(self.workspace_folder, exist_ok=True)
        
        # Set workspace context for tools to use
        workspace_context.set_workspace(self.workspace_folder)
        
        self.console.print(f"✅ Created workspace folder: {self.workspace_folder}")
        self.console.print(f"✅ Workspace context set: {workspace_context}")
        
    def install_dependencies(self):
        """Auto-install required dependencies"""
        self.console.print("✅ Dependencies ready")
```

### Auto-Generated .env File
```
ANTHROPIC_API_KEY=your_api_key_here
ANTHROPIC_BASE_URL=https://api.anthropic.com
ANTHROPIC_MODEL_NAME=claude-4-sonnet-20250514
MAX_TURNS=100
SYSTEM_PROMPT_FILE=system_prompt.txt
```

### File Structure
```
chat.py
```

## Workspace Management

### Isolated Session Folders
Each new run creates a unique workspace folder to keep sessions organized and isolated:

```
workspace/
├── session_20241201_143022/  # Timestamp-based folder
│   ├── files created by agent
│   ├── scripts generated
│   └── output files
├── session_20241201_151045/  # Another session
│   ├── different files
│   └── different outputs
└── session_20241201_162130/  # Yet another session
    └── more files
```

### Implementation Details
- **Automatic Creation**: Each chat startup creates a new `workspace/session_YYYYMMDD_HHMMSS/` folder
- **Isolated Environment**: All file operations are contained within the session folder
- **Clean Separation**: No cross-contamination between different sessions
- **Easy Management**: Users can easily find and manage files from specific sessions
- **Working Directory**: The agent automatically sets the session folder as the working directory

## Complete Project Structure

```
ai_agent/
├── model_provider.py
├── tools.py
├── agent.py
├── chat.py
├── main.py
├── system_prompt.txt
├── requirements.txt
├── .env (auto-created)
└── workspace/ (auto-created)
    ├── session_20241201_143022/
    ├── session_20241201_151045/
    └── session_20241201_162130/
```

## Custom Endpoint Support

The system supports custom Anthropic API endpoints:

### Environment Variables
- `ANTHROPIC_API_KEY`: API key for Anthropic
- `ANTHROPIC_BASE_URL`: Custom API endpoint (e.g., Anthropic API, custom proxy, local server)
- `ANTHROPIC_MODEL_NAME`: Model name to use (e.g., claude-4-opus-20250514, claude-4-sonnet-20250514)
- `MAX_TURNS`: Maximum number of turns in the agent conversation loop (default: 100)

### Supported Endpoints
- **Anthropic API**: Use `https://api.anthropic.com` as base URL
- **Custom Proxies**: Route requests through corporate proxies or middleware
- **Local Models**: Connect to local model servers compatible with Anthropic API
- **Compatible APIs**: Any Anthropic-compatible API endpoint

### Implementation Notes
- The `AnthropicModelProvider` class handles endpoint configuration
- Automatic client creation with custom base URLs and API keys
- Fallback to default Anthropic API if no custom endpoint is specified
- Full compatibility with Anthropic's tool calling features

## Usage Example

### Main.py Implementation
```python
import asyncio
import os
from dotenv import load_dotenv
from agent import ChatAgent
from chat import AgentChat
from tools import get_anthropic_tools, get_tool_functions

# Load environment variables
load_dotenv()

async def main():
    """Main entry point for the AI agent system"""
    # Create chat agent
    chat_agent = ChatAgent(
        system_prompt_file="system_prompt.txt",
        model_name=os.getenv("ANTHROPIC_MODEL_NAME", "claude-4-sonnet-20250514")
    )
    
    # Import and register all tools
    tools = get_anthropic_tools()
    tool_functions = get_tool_functions()
    chat_agent.register_tools(tools, tool_functions)
    
    # Create chat interface
    chat = AgentChat(chat_agent)
    
    # Start interactive chat
    await chat.start()

if __name__ == "__main__":
    asyncio.run(main())
```

### Terminal Output
```bash
$ python main.py

🤖 AI Agent Chat v1.0 (Anthropic API)
✅ Created .env file
✅ Created workspace folder: workspace/session_20241201_143022/
✅ Dependencies ready

Welcome! Start chatting or type /exit to exit.
Working directory: workspace/session_20241201_143022/

> Can you create a simple Python web server with a calculator webpage?

🤖 I'll create a simple Python web server with a calculator webpage for you!

[TOOL][create_file] file_path=server.py, content_length=1247
[TOOL][create_file] file_path=calculator.html, content_length=2156
[TOOL][execute_python_file] file_path=server.py
✅ Tools executed successfully

Perfect! I've created a simple web server with:
- Python HTTP server on port 8000
- Calculator webpage with HTML/CSS/JavaScript
- Basic arithmetic operations
- Clean responsive design

Server is running at http://localhost:8000

> /exit
Goodbye! 👋
```

## Requirements File

```
anthropic>=0.20.0
python-dotenv>=1.0.0
colorama>=0.4.6
rich>=13.0.0
psutil
```

## System Prompt Template

The system will automatically load from `system_prompt.txt` if it exists. If no file is found, it falls back to a default prompt:
```
You are a helpful AI coding assistant with access to file operations and code execution tools.
```

Users should provide their own `system_prompt.txt` file with their preferred prompt. The system only creates a fallback when no file exists.

## Implementation Steps

1. **Phase 1 - Model Provider**: Create the custom model provider using Anthropic client in `model_provider.py`
2. **Phase 2 - Agent**: Create the agent loop with Anthropic API and tool calling in `agent.py`
3. **Phase 3 - Tools**: Implement all tools using Anthropic's tool specification format in `tools.py`
4. **Phase 4 - Chat**: Build the interactive REPL interface with auto-setup in `chat.py`
5. **Phase 5 - Workspace**: Implement automatic workspace folder creation for each session
6. **Phase 6 - Dependencies**: Auto-install required dependencies on first run
7. **Phase 7 - Integration**: Connect all components and test with Anthropic API
8. **Phase 8 - Polish**: Add error handling, documentation, and final testing

## Key Features

### Tool System
- ✅ User communication and notification system
- ✅ Comprehensive file operations (create, read, modify, delete)
- ✅ Code execution (Python, shell commands)
- ✅ Detailed logging for all operations
- ✅ Error handling with meaningful messages
- ✅ Anthropic tool calling format support

### Agent Loop
- ✅ Anthropic API integration for conversation
- ✅ Custom model provider integration for custom endpoints
- ✅ Tool calling and result handling with Anthropic format
- ✅ Multi-turn conversation support
- ✅ Context and history management
- ✅ System prompt loading from file

### Chat Interface
- ✅ Interactive command-line REPL interface
- ✅ Auto-environment setup (.env creation)
- ✅ Automatic workspace folder creation for each session
- ✅ Automatic dependency installation
- ✅ Colored output and rich formatting
- ✅ Real-time tool execution display
- ✅ Exit command support
- ✅ Error handling and recovery

## Integration with Anthropic API

The system uses direct Anthropic API calls with tool calling:

```python
# Example usage in main.py
async def main():
    # Create chat agent
    chat_agent = ChatAgent(
        system_prompt_file="system_prompt.txt",
        model_name=os.getenv("ANTHROPIC_MODEL_NAME", "claude-4-sonnet-20250514")
    )
    
    # Register tools
    tools = get_anthropic_tools()  # Import all tools from tools.py
    tool_functions = get_tool_functions()  # Import function mappings
    chat_agent.register_tools(tools, tool_functions)
    
    # Run conversation
    user_input = "Create a simple Python web server with a calculator"
    response = await chat_agent.run_conversation(user_input)
    print(response)

# The ChatAgent class handles the Anthropic API integration internally:
# - Uses custom model provider for custom endpoints
# - Manages conversation state and history
# - Handles tool execution and results
```

### Custom Endpoint Configuration Example

To use a custom endpoint, users can modify the `.env` file:
```
ANTHROPIC_API_KEY=your_api_key_here
ANTHROPIC_BASE_URL=https://your-custom-api.com
ANTHROPIC_MODEL_NAME=claude-4-sonnet-20250514
MAX_TURNS=100
SYSTEM_PROMPT_FILE=system_prompt.txt
```

## Final Instructions

1. **Start with model provider**: Create the custom model provider using Anthropic client in `model_provider.py`
2. **Create agent**: Create the Anthropic API conversation loop with tool calling in `agent.py`
3. **Implement tools**: Implement all 12 tools using Anthropic's tool specification format in `tools.py`
4. **Add chat interface**: Build the interactive REPL interface with auto-setup in `chat.py`
5. **Add workspace management**: Implement automatic workspace folder creation for each session
6. **Add auto-installation**: Include dependency installation in the chat startup
7. **Test thoroughly**: Ensure all components work together with Anthropic API
8. **Document**: Add clear documentation and usage examples

The final system should be a complete, production-ready AI coding agent that uses Anthropic's API with tool calling for custom endpoint support and advanced reasoning capabilities.

Don't create other files and keep project simple. Never change existing system_prompt.txt file.

## Important
User has already set the .env as required. You should create .venv and install all dependencies in .venv. 
And run main.py with prompt "Create your favorite web game into a unique and innovative style, and then launch it." to show the result 